{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_KOBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1MKQKhNbn1Rx81woa_CpaNH-ppgGJRzSs",
      "authorship_tag": "ABX9TyOXYzgcyaJ9vBoMORWKw8LT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python_defaultSpec_1600400072374",
      "display_name": "Python 3.6.10 64-bit ('python3': conda)"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d9ffe36bfb04d87b1c5d35be757c544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca604de3dd1042edb09d548ce9f0fb85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a0a4bbc47984955bdbdefb39f949445",
              "IPY_MODEL_3646e70cfc2b43afa2c8bf36763855fb"
            ]
          }
        },
        "ca604de3dd1042edb09d548ce9f0fb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a0a4bbc47984955bdbdefb39f949445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e5f137c774c457db6d2eca28c878525",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 16098,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f159126f7dd4a728765c6f7d88d3348"
          }
        },
        "3646e70cfc2b43afa2c8bf36763855fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35274065ebf44249b76c3f3c559ee03c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/16098 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8923a1b19b8c4fe9b16226782220e419"
          }
        },
        "1e5f137c774c457db6d2eca28c878525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f159126f7dd4a728765c6f7d88d3348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35274065ebf44249b76c3f3c559ee03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8923a1b19b8c4fe9b16226782220e419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRVxx3skW6bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83e54251-c828-41ee-a4d9-16d2ff4e261d",
        "tags": []
      },
      "source": [
        "!pip install mxnet-cu101\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install transformers==2.1.1\n",
        "!pip install torch==1.3.1\n",
        "!pip install tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: mxnet-cu101 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.7.0)\nRequirement already satisfied: requests<3,>=2.20.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (2.23.0)\nRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (0.8.4)\nRequirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (1.18.1)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.4.5.2)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.25.8)\nRequirement already satisfied: gluonnlp in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.0)\nRequirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.3)\nRequirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (4.44.1)\nRequirement already satisfied: numpy>=1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (1.18.1)\nRequirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (20.3)\nRequirement already satisfied: cython in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (0.29.15)\nRequirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2019.3)\nRequirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->gluonnlp) (2.4.6)\nRequirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->gluonnlp) (1.14.0)\nRequirement already satisfied: sentencepiece==0.1.85 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.85)\nRequirement already satisfied: transformers==2.1.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.1.1)\nRequirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (0.0.43)\nRequirement already satisfied: regex in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (2020.7.14)\nRequirement already satisfied: requests in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (2.23.0)\nRequirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (4.44.1)\nRequirement already satisfied: sentencepiece in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (0.1.85)\nRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (1.18.1)\nRequirement already satisfied: boto3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (1.14.5)\nRequirement already satisfied: click in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (7.1.1)\nRequirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (0.14.1)\nRequirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (1.14.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (1.25.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2020.4.5.2)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2.9)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.3.3)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.9.4)\nRequirement already satisfied: botocore<1.18.0,>=1.17.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (1.17.5)\nRequirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->transformers==2.1.1) (0.15.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->transformers==2.1.1) (2.8.1)\nRequirement already satisfied: torch==1.3.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.3.1)\nRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from torch==1.3.1) (1.18.1)\nRequirement already satisfied: tensorflow in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.3.0)\nRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.18.1)\nRequirement already satisfied: absl-py>=0.7.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.10.0)\nRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: scipy==1.4.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: tensorboard<3,>=2.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: astunparse==1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: wheel>=0.26 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.34.2)\nRequirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.14.0)\nRequirement already satisfied: gast==0.3.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.3.3)\nRequirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.12.2)\nRequirement already satisfied: grpcio>=1.8.6 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.32.0)\nRequirement already satisfied: google-pasta>=0.1.8 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.10.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nRequirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\nRequirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.1.3.post20200330)\nRequirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.4.5.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\nRequirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\nRequirement already satisfied: pyasn1>=0.1.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTOcRO-HW7lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "402ce351-9a76-494f-8f3a-c64a592b61c4",
        "tags": []
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting git+https://****@github.com/SKTBrain/KoBERT.git\n  Cloning https://****@github.com/SKTBrain/KoBERT.git to /tmp/pip-req-build-pskg6150\n  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-pskg6150\nRequirement already satisfied (use --upgrade to upgrade): kobert==0.1.1 from git+https://****@github.com/SKTBrain/KoBERT.git in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages\nBuilding wheels for collected packages: kobert\n  Building wheel for kobert (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kobert: filename=kobert-0.1.1-py3-none-any.whl size=12824 sha256=29bff39daed4765caba60411baca442b1ef408ad65d5ed8127926060bbd000b1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-w33xf7hy/wheels/90/2a/41/0f155274a74cda10ff58f33cd4db2bfc5437d00f0f9ecb242f\nSuccessfully built kobert\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZjVJ7ObPaDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPLbjP-XWOfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import WarmupLinearSchedule\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFLHAyaeWTxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GPU ÏÇ¨Ïö© Ïãú\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJD7LDooUnW1",
        "colab_type": "text"
      },
      "source": [
        "# **SKT Ï†úÍ≥µ KoBert Ïù¥Ïö©**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2BPpbLtWYZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c23bb141-639e-45ea-fd22-b5fb8f86b914",
        "tags": []
      },
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using cached model\nusing cached model\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFgqWNdqNm2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/Dataset/gender_train_data.csv'\n",
        "test_path = '/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/Dataset/gender_test_data.csv'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR98zFGE_m-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0de44135-841b-476a-f8f6-d9c26a764c1a"
      },
      "source": [
        "train_data = pd.read_csv(train_path, engine='python', encoding='utf-8', index_col=0)\n",
        "test_data = pd.read_csv(test_path, engine='python', encoding='utf-8', index_col=0)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(158754, 39688)"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H28zlM2l_47S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a5f7071-8d0e-4cfb-d08e-c7fe454e5c32"
      },
      "source": [
        "train_data = train_data.dropna()\n",
        "train_data = train_data.reset_index()\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "test_data = test_data.dropna()\n",
        "test_data = test_data.reset_index()\n",
        "test_data = test_data.drop(['index'], axis=1)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(154204, 38515)"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIC9Pha1AG9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "102b8f7b-06d1-4863-8c75-12c7a61b118b",
        "tags": []
      },
      "source": [
        "dataset_train = []\n",
        "for i in tqdm(range(len(train_data))):\n",
        "    dataset_train.append([train_data['content'][i], int(train_data['label'][i])])\n",
        "dataset_train[:5]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154204/154204 [00:05<00:00, 30051.29it/s]\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[\"_ùòΩùôçùôäùôíùòΩùôîùôÖùôê ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä Í≥†Í∞ùÎãòÎì§ÏùÑ ÏúÑÌïú ÏÜåÎèÖÏ†§ + Ìï∏ÎìúÌÅ¨Î¶º ÏÑ∏ÌåÖÏôÑÎ£å üñ§ ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä Î©ÄÎ¶¨ÏÑú Ï±ôÍ≤®Ï£ºÎäî ÏπúÍµ¨Îì§ ÎçïÎ∂ÑÏóê Îì†Îì†Ìûà ÏÜåÎèÖÏ†úÌíàÍ≥º Î≥¥ÏäµÏ†ú ÏüÅÏó¨ÎíÄÏäµÎãàÎã§ üòäüòä ÎßàÏùåÍπåÏßÄ ÌíçÏ°±Ìï¥Ï°åÏñ¥Ïöî‚ù£‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ÏΩîÎ°úÎÇòÍ∞Ä ÌïòÎ£® Îπ®Î¶¨ Ïû†Ïû¨ÏõåÏßÄÍ∏∏ Î∞îÎùºÎ©∞.Ï†ÄÏùò Î∞îÎûå, Î™®ÎëêÏùò Î∞îÎûå, üôè‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä Îß§Ïùº Îß§Ïùº ÏÇ¥Í∑† ÏÜåÎèÖÌïòÍ≥† ÏûàÏñ¥Ïöî üñ§‚†Ä‚†Ä‚†Ä‚†Ä ÏïàÏã¨ÌïòÍ≥† Î∞©Î¨∏ÌïòÏÑ∏Ïöî üñ§ „Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö° ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚ùõ BROWBYJU ‚ùú ÎßåÏùò ÏïΩÏÜç ‚†Ä ‚Ä¢ ÏùºÌöåÏö©Ìíà ÏãúÏà† ÌõÑ Î∞îÎ°ú ÌèêÍ∏∞ ‡∑Ü ‚Ä¢ ÏñºÍµ¥Ìòï, ÌîºÎ∂ÄÏÉÅÌÉú, Í≥®Í≤© Îì±Ïóê ÎßûÍ≤å 1:1 ÎßûÏ∂§ÏãúÏà† ‡∑Ü ‚Ä¢ ÌîÑÎùºÏù¥ÎπóÌïú Í≥µÍ∞ÑÏóêÏÑú ÏãúÏà† ‡∑Ü ‚Ä¢ ÏµúÏÉÅÍ∏â Ïû¨Î£å ÏóÑÏÑ† ‡∑Ü ‚Ä¢ Ïú†ÏßÄÍ∏∞Í∞Ñ ÌèâÍ∑† 8Í∞úÏõî ~ 1ÎÖÑ 6Í∞úÏõî ‡∑Ü ‚Ä¢ ÏãúÏà† ÏßÅÌõÑ ÌÜµÏ¶ùÏù¥ Í±∞Ïùò ÏóÜÎäî 90% Î¨¥ÌÜµÏãúÏà† ‡∑Ü ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä ‚ùõ ÏòàÏïΩ Î∞è ÏÉÅÎã¥ ‚ùú ‚†Ä Ïπ¥Ïπ¥Ïò§ÌÜ° ÌîåÎü¨Ïä§ÏπúÍµ¨ Í≤ÄÏÉâ üîç 'Î∏åÎ°úÎ∞îÏù¥Ï•¨' Ïù∏Ïä§ÌÉÄÍ∑∏Îû® üíΩ @_brow_by_ju_  „Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°„Ö°\",\n  1],\n ['Ïù¥Ï†ú ÏßëÎì§Ïù¥ Í∑∏ÎßåÌï†ÎûòÏöî.. #ÏßëÎì§Ïù¥ #Ïù¥ÏÇ¨ #ÎπöÎçîÎØ∏ #ÏπúÍµ¨Îì§ #ÏïÑÍ∑∏ÏôÄ #ÎîîÏïÑÎ∏îÎ°ú  #ÌôàÏä§ÌÉÄÍ∑∏Îû® #ÏπµÌÖåÏùº', 0],\n ['Ï†ïÏã†ÏóÜÏù¥ Î∞îÏÅòÎçîÎãà Î™áÏ£ºÍ∞Ä ÏßÄÎÇ¨Îã§‚†Ä ÏãúÍ∞ÑÏù¥ÎÇòÎ©¥ ÏùΩÏñ¥ÏïºÏßÄ ÌñàÎçò ‚ÄòÏ£ΩÏùå‚Äô Ïù∏Îç∞ ÌïëÍ≥ÑÍ∞Ä ÎßéÏúºÎãà Ïù¥Ï†úÏÑúÏïº ÏÜêÏóê Ï•êÏóàÎã§ÌãàÎÇ†ÎïåÎßàÎã§ Ï°∞Í∏àÏî© ÏùΩÏñ¥ÏïºÏßÄüìó #Î≤†Î•¥ÎÇòÎ•¥Î≤†Î•¥Î≤†Î•¥ #Ï£ΩÏùå #Ï±Ö #ÎèÑÏÑú #ÎèÖÏÑú #Ï±ÖÏ∂îÏ≤ú #Ï±ÖÏ∂îÏ≤úÌï¥Ï£ºÏÑ∏Ïöî',\n  0],\n ['ÏûÖÏúºÎ©¥ #ÌïòÎäòÌïòÎäò ÎÇ†ÏïÑÍ∞àÎìØ Ìïú #Î¶∞ÎÑ® ÏÜåÏû¨Ïùò #ÌîåÎùºÏõå #Ïä§Ïª§Ìä∏ ÏûÖÎãàÎã§.  #ÌîÑÎ°úÎ∞©Ïä§ Ïä§Ïª§Ìä∏ ÏôÄ Ìï®Íªò #6Ïõî ÌñâÎ≥µÌïú ÌïúÎã¨ ÎêòÏÑ∏Ïöî  #ootd#oufit#likeforlikes#black#dailylook#daily',\n  1],\n ['Ïó∞Ï£º)ÏùÄÏ±Ñ ÎçïÎ∂ÑÏóê ÏßÄÍ∏à Ïò¨Î¶¨Îäî 20ÎÖÑ 1Ïõî 30Ïùº Ïû†ÏùÑ 10ÏãúÍ∞ÑÏî© ÏûêÎäî Í≥†2.. ÎßêÎèÑÏïàÎèº Ïû† Ï§ÑÏù¥Ïûêüåä ‚Ä¢ ‚Ä¢ ‚Ä¢  #03 #03ÎÖÑÏÉù #18 #18ÏÇ¥ #Í≥†1 #Í≥†2 #ÏòàÎπÑÍ≥†2 #2020 #Í≤®Ïö∏Î∞©Ìïô #Í≥µÏä§ÌÉÄÍ∑∏Îû® #Î®πÏä§ÌÉÄÍ∑∏Îû® #Í≥µÏä§ÌÉÄ #Î®πÏä§ÌÉÄ #Ï¢ãÏïÑÏöîÎ∞òÏÇ¨ #ÎßûÌåî #Í≥µÏä§ÌÉÄÎßûÌåî #Í≥µÏä§ÌÉÄÍ∑∏Îû®ÎßûÌåî #ÌîåÎûòÎÑà #Î™®Ìä∏Î™®Ìä∏ #Ïú§Îî¥Îî¥ #Í≤®Ïö∏ÏùÑÍ±∑ÎäîÎã§ #Ïù¥Í≥ºÏÉùÍ≥µÏä§ÌÉÄ #ÏπòÏ¶àÎ≥º #Í∞àÏπò #Í∞úÌïô',\n  1]]"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZyl99XqAWd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "a3eabbcb-e269-44a7-cf92-310d5e11c178",
        "tags": []
      },
      "source": [
        "dataset_test = []\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    dataset_test.append([test_data['content'][i], int(test_data['label'][i])])\n",
        "dataset_test[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38515/38515 [00:01<00:00, 32564.85it/s]\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[['Í≥†ÎßôÏäµÎãàÎã§:) Ïó¥Î¨¥ÏóÑÎßàüòò #ÏïÑÏù¥Ïø†Î≠òÏù¥Îü∞Í±∏ #ÏïÑÍπåÏõåÏÑúÏì∞Í≤†ÎÇòüôä #ÏÉùÏùºÏÑ†Î¨º #Î∞úÎ†åÌÉÄÏù∏ÏΩúÎùºÎ≥¥ #bottegaveneta #Î≥¥ÌÖåÍ∞Ä #ÌôçÏó∞Ïù¥ÏÉùÏùºÎïåÏñ¥Îñ°ÌïòÏßÄüòî',\n  0],\n ['Ï†úÏûÑÏä§ Ïó¥Î¨¥ #007 #Í≥†ÏñëÏù¥ #cat #kitten', 0],\n ['ÏñëÏπòÍ∏∞ ÏÜåÏπòÍ∏∞ Ïã¨Î∞î', 0],\n ['Ïó¨ÏπúÏù¥ Ï∞çÏñ¥Ï£ºÎäî ÏÇ¨ÏßÑ vs ÎÇ®ÏπúÏù¥ Ï∞çÏñ¥Ï£ºÎäî ÏÇ¨ÏßÑ... Ìú¥....üòí #ÏßëÎì§Ïù¥ #ÏÇ¨ÏßÑ #Ï∞®Ïù¥Î≥¥ÏÜå #ÏûòÎÜÄÎã§Í∞ëÎãàÎã§üôå', 0],\n ['ÏûêÏó∞Í¥ëÏóêÏÑú ÏÇ¨ÏßÑÏ∞çÍ≥†Ïã∂ÏùÄÎç∞„Öã„Öã„ÖãÏöîÏ¶ò ÎÇÆÏóê ÌôîÏû•ÌïòÍ≥† Î∞ñÏóê ÎÇòÍ∞àÏùºÏù¥ Í±∞Ïùò ÏóÜÏùë..„Öã„Öã„Öã ÎπÑÌÉÄÎØºD Ï±ôÍ≤®Î®πÏñ¥ÏïºÏßÄ„Öã„Öã„Öã', 0]]"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzEhdkxMZYuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69a059f2-9e22-487f-b0c6-02d7e8fee350",
        "tags": []
      },
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using cached model\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnFE5quZucZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86roomBJZwlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 3\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59ufYG9ZyUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghCa_b5tZ2ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3J23QtsbhAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=4,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq2R7H4kbjpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "941730fa-9ebf-4f45-8ab4-ebe1ef9b2d2b"
      },
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUwLbXabxD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnsr21WbzCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZunYoGSb0dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkGPXmy5b1uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_step, t_total=t_total)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CIBs40Ib3J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/model_checkpoint/\".format(num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7gsf1Gb4Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "8d9ffe36bfb04d87b1c5d35be757c544",
            "ca604de3dd1042edb09d548ce9f0fb85",
            "6a0a4bbc47984955bdbdefb39f949445",
            "3646e70cfc2b43afa2c8bf36763855fb",
            "1e5f137c774c457db6d2eca28c878525",
            "4f159126f7dd4a728765c6f7d88d3348",
            "35274065ebf44249b76c3f3c559ee03c",
            "8923a1b19b8c4fe9b16226782220e419"
          ]
        },
        "outputId": "18d637b0-bba3-4b8a-9836-fc092112fca0",
        "tags": []
      },
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    # Î™®Îç∏ ÌèâÍ∞Ä\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "    # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•\n",
        "    torch.save(model, PATH + 'model{}.pt'.format(num_epochs))  # Ï†ÑÏ≤¥ Î™®Îç∏ Ï†ÄÏû•\n",
        "    torch.save(model.state_dict(), PATH + 'model_state_dict{}.pt'.format(num_epochs))  # Î™®Îç∏ Í∞ùÏ≤¥Ïùò state_dict Ï†ÄÏû•\n",
        "    torch.save({\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict()\n",
        "                }, PATH + 'all.tar')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \"\"\"\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2410.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9858bd49c85e44fcab2d782c7a7fab21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "epoch 1 batch id 1 loss 1.411845088005066 train acc 0.203125\nepoch 1 batch id 201 loss 0.6219913959503174 train acc 0.605488184079602\nepoch 1 batch id 401 loss 0.5244743227958679 train acc 0.6225841645885287\nepoch 1 batch id 601 loss 0.6364520192146301 train acc 0.6391430948419301\nepoch 1 batch id 801 loss 0.645945131778717 train acc 0.6546504369538078\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-43dba8ebf3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}