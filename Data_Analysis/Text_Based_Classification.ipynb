{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_KOBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1MKQKhNbn1Rx81woa_CpaNH-ppgGJRzSs",
      "authorship_tag": "ABX9TyOXYzgcyaJ9vBoMORWKw8LT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python_defaultSpec_1600400072374",
      "display_name": "Python 3.6.10 64-bit ('python3': conda)"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d9ffe36bfb04d87b1c5d35be757c544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca604de3dd1042edb09d548ce9f0fb85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a0a4bbc47984955bdbdefb39f949445",
              "IPY_MODEL_3646e70cfc2b43afa2c8bf36763855fb"
            ]
          }
        },
        "ca604de3dd1042edb09d548ce9f0fb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a0a4bbc47984955bdbdefb39f949445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e5f137c774c457db6d2eca28c878525",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 16098,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f159126f7dd4a728765c6f7d88d3348"
          }
        },
        "3646e70cfc2b43afa2c8bf36763855fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35274065ebf44249b76c3f3c559ee03c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/16098 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8923a1b19b8c4fe9b16226782220e419"
          }
        },
        "1e5f137c774c457db6d2eca28c878525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f159126f7dd4a728765c6f7d88d3348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35274065ebf44249b76c3f3c559ee03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8923a1b19b8c4fe9b16226782220e419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRVxx3skW6bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83e54251-c828-41ee-a4d9-16d2ff4e261d",
        "tags": []
      },
      "source": [
        "!pip install mxnet-cu101\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install transformers==2.1.1\n",
        "!pip install torch==1.3.1\n",
        "!pip install tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: mxnet-cu101 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.7.0)\nRequirement already satisfied: requests<3,>=2.20.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (2.23.0)\nRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (0.8.4)\nRequirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu101) (1.18.1)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.4.5.2)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.25.8)\nRequirement already satisfied: gluonnlp in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.0)\nRequirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.3)\nRequirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (4.44.1)\nRequirement already satisfied: numpy>=1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (1.18.1)\nRequirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (20.3)\nRequirement already satisfied: cython in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from gluonnlp) (0.29.15)\nRequirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2019.3)\nRequirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->gluonnlp) (2.4.6)\nRequirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->gluonnlp) (1.14.0)\nRequirement already satisfied: sentencepiece==0.1.85 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.85)\nRequirement already satisfied: transformers==2.1.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.1.1)\nRequirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (0.0.43)\nRequirement already satisfied: regex in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (2020.7.14)\nRequirement already satisfied: requests in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (2.23.0)\nRequirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (4.44.1)\nRequirement already satisfied: sentencepiece in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (0.1.85)\nRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (1.18.1)\nRequirement already satisfied: boto3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers==2.1.1) (1.14.5)\nRequirement already satisfied: click in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (7.1.1)\nRequirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (0.14.1)\nRequirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (1.14.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (1.25.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2020.4.5.2)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2.9)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.3.3)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.9.4)\nRequirement already satisfied: botocore<1.18.0,>=1.17.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (1.17.5)\nRequirement already satisfied: docutils<0.16,>=0.10 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->transformers==2.1.1) (0.15.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3->transformers==2.1.1) (2.8.1)\nRequirement already satisfied: torch==1.3.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (1.3.1)\nRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from torch==1.3.1) (1.18.1)\nRequirement already satisfied: tensorflow in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.3.0)\nRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.18.1)\nRequirement already satisfied: absl-py>=0.7.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.10.0)\nRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: scipy==1.4.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: tensorboard<3,>=2.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: astunparse==1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: wheel>=0.26 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.34.2)\nRequirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.14.0)\nRequirement already satisfied: gast==0.3.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.3.3)\nRequirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.12.2)\nRequirement already satisfied: grpcio>=1.8.6 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.32.0)\nRequirement already satisfied: google-pasta>=0.1.8 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.10.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nRequirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\nRequirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.1.3.post20200330)\nRequirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.4.5.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\nRequirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\nRequirement already satisfied: pyasn1>=0.1.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTOcRO-HW7lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "402ce351-9a76-494f-8f3a-c64a592b61c4",
        "tags": []
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting git+https://****@github.com/SKTBrain/KoBERT.git\n  Cloning https://****@github.com/SKTBrain/KoBERT.git to /tmp/pip-req-build-pskg6150\n  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-pskg6150\nRequirement already satisfied (use --upgrade to upgrade): kobert==0.1.1 from git+https://****@github.com/SKTBrain/KoBERT.git in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages\nBuilding wheels for collected packages: kobert\n  Building wheel for kobert (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kobert: filename=kobert-0.1.1-py3-none-any.whl size=12824 sha256=29bff39daed4765caba60411baca442b1ef408ad65d5ed8127926060bbd000b1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-w33xf7hy/wheels/90/2a/41/0f155274a74cda10ff58f33cd4db2bfc5437d00f0f9ecb242f\nSuccessfully built kobert\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZjVJ7ObPaDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPLbjP-XWOfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import WarmupLinearSchedule\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFLHAyaeWTxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJD7LDooUnW1",
        "colab_type": "text"
      },
      "source": [
        "# **SKT 제공 KoBert 이용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2BPpbLtWYZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c23bb141-639e-45ea-fd22-b5fb8f86b914",
        "tags": []
      },
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using cached model\nusing cached model\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFgqWNdqNm2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/Dataset/gender_train_data.csv'\n",
        "test_path = '/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/Dataset/gender_test_data.csv'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR98zFGE_m-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0de44135-841b-476a-f8f6-d9c26a764c1a"
      },
      "source": [
        "train_data = pd.read_csv(train_path, engine='python', encoding='utf-8', index_col=0)\n",
        "test_data = pd.read_csv(test_path, engine='python', encoding='utf-8', index_col=0)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(158754, 39688)"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H28zlM2l_47S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a5f7071-8d0e-4cfb-d08e-c7fe454e5c32"
      },
      "source": [
        "train_data = train_data.dropna()\n",
        "train_data = train_data.reset_index()\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "test_data = test_data.dropna()\n",
        "test_data = test_data.reset_index()\n",
        "test_data = test_data.drop(['index'], axis=1)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(154204, 38515)"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIC9Pha1AG9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "102b8f7b-06d1-4863-8c75-12c7a61b118b",
        "tags": []
      },
      "source": [
        "dataset_train = []\n",
        "for i in tqdm(range(len(train_data))):\n",
        "    dataset_train.append([train_data['content'][i], int(train_data['label'][i])])\n",
        "dataset_train[:5]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 154204/154204 [00:05<00:00, 30051.29it/s]\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[\"_𝘽𝙍𝙊𝙒𝘽𝙔𝙅𝙐 ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ 고객님들을 위한 소독젤 + 핸드크림 세팅완료 🖤 ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ 멀리서 챙겨주는 친구들 덕분에 든든히 소독제품과 보습제 쟁여뒀습니다 😊😊 마음까지 풍족해졌어요❣⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ 코로나가 하루 빨리 잠재워지길 바라며.저의 바람, 모두의 바람, 🙏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ 매일 매일 살균 소독하고 있어요 🖤⠀⠀⠀⠀ 안심하고 방문하세요 🖤 ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ❛ BROWBYJU ❜ 만의 약속 ⠀ • 일회용품 시술 후 바로 폐기 ෆ • 얼굴형, 피부상태, 골격 등에 맞게 1:1 맞춤시술 ෆ • 프라이빗한 공간에서 시술 ෆ • 최상급 재료 엄선 ෆ • 유지기간 평균 8개월 ~ 1년 6개월 ෆ • 시술 직후 통증이 거의 없는 90% 무통시술 ෆ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ❛ 예약 및 상담 ❜ ⠀ 카카오톡 플러스친구 검색 🔍 '브로바이쥬' 인스타그램 💽 @_brow_by_ju_  ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\",\n  1],\n ['이제 집들이 그만할래요.. #집들이 #이사 #빚더미 #친구들 #아그와 #디아블로  #홈스타그램 #칵테일', 0],\n ['정신없이 바쁘더니 몇주가 지났다⠀ 시간이나면 읽어야지 했던 ‘죽음’ 인데 핑계가 많으니 이제서야 손에 쥐었다틈날때마다 조금씩 읽어야지📗 #베르나르베르베르 #죽음 #책 #도서 #독서 #책추천 #책추천해주세요',\n  0],\n ['입으면 #하늘하늘 날아갈듯 한 #린넨 소재의 #플라워 #스커트 입니다.  #프로방스 스커트 와 함께 #6월 행복한 한달 되세요  #ootd#oufit#likeforlikes#black#dailylook#daily',\n  1],\n ['연주)은채 덕분에 지금 올리는 20년 1월 30일 잠을 10시간씩 자는 고2.. 말도안돼 잠 줄이자🌊 • • •  #03 #03년생 #18 #18살 #고1 #고2 #예비고2 #2020 #겨울방학 #공스타그램 #먹스타그램 #공스타 #먹스타 #좋아요반사 #맞팔 #공스타맞팔 #공스타그램맞팔 #플래너 #모트모트 #윤딴딴 #겨울을걷는다 #이과생공스타 #치즈볼 #갈치 #개학',\n  1]]"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZyl99XqAWd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "a3eabbcb-e269-44a7-cf92-310d5e11c178",
        "tags": []
      },
      "source": [
        "dataset_test = []\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    dataset_test.append([test_data['content'][i], int(test_data['label'][i])])\n",
        "dataset_test[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 38515/38515 [00:01<00:00, 32564.85it/s]\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[['고맙습니다:) 열무엄마😘 #아이쿠뭘이런걸 #아까워서쓰겠나🙊 #생일선물 #발렌타인콜라보 #bottegaveneta #보테가 #홍연이생일때어떡하지😔',\n  0],\n ['제임스 열무 #007 #고양이 #cat #kitten', 0],\n ['양치기 소치기 심바', 0],\n ['여친이 찍어주는 사진 vs 남친이 찍어주는 사진... 휴....😒 #집들이 #사진 #차이보소 #잘놀다갑니다🙌', 0],\n ['자연광에서 사진찍고싶은데ㅋㅋㅋ요즘 낮에 화장하고 밖에 나갈일이 거의 없응..ㅋㅋㅋ 비타민D 챙겨먹어야지ㅋㅋㅋ', 0]]"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzEhdkxMZYuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69a059f2-9e22-487f-b0c6-02d7e8fee350",
        "tags": []
      },
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using cached model\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnFE5quZucZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86roomBJZwlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 3\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59ufYG9ZyUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghCa_b5tZ2ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3J23QtsbhAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=4,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq2R7H4kbjpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "941730fa-9ebf-4f45-8ab4-ebe1ef9b2d2b"
      },
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUwLbXabxD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnsr21WbzCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZunYoGSb0dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkGPXmy5b1uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_step, t_total=t_total)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CIBs40Ib3J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"/home/lab12/workspace/Insta_User_Profiling/Data_Analysis/model_checkpoint/\".format(num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7gsf1Gb4Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "8d9ffe36bfb04d87b1c5d35be757c544",
            "ca604de3dd1042edb09d548ce9f0fb85",
            "6a0a4bbc47984955bdbdefb39f949445",
            "3646e70cfc2b43afa2c8bf36763855fb",
            "1e5f137c774c457db6d2eca28c878525",
            "4f159126f7dd4a728765c6f7d88d3348",
            "35274065ebf44249b76c3f3c559ee03c",
            "8923a1b19b8c4fe9b16226782220e419"
          ]
        },
        "outputId": "18d637b0-bba3-4b8a-9836-fc092112fca0",
        "tags": []
      },
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    # 모델 평가\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "    # 체크포인트 저장\n",
        "    torch.save(model, PATH + 'model{}.pt'.format(num_epochs))  # 전체 모델 저장\n",
        "    torch.save(model.state_dict(), PATH + 'model_state_dict{}.pt'.format(num_epochs))  # 모델 객체의 state_dict 저장\n",
        "    torch.save({\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict()\n",
        "                }, PATH + 'all.tar')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \"\"\"\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2410.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9858bd49c85e44fcab2d782c7a7fab21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "epoch 1 batch id 1 loss 1.411845088005066 train acc 0.203125\nepoch 1 batch id 201 loss 0.6219913959503174 train acc 0.605488184079602\nepoch 1 batch id 401 loss 0.5244743227958679 train acc 0.6225841645885287\nepoch 1 batch id 601 loss 0.6364520192146301 train acc 0.6391430948419301\nepoch 1 batch id 801 loss 0.645945131778717 train acc 0.6546504369538078\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-43dba8ebf3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}